{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Expansion for Optimizing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Ollama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Large Language Model (LLM) is a type of artificial intelligence (AI) model that uses machine learning algorithms to process and generate human-like text. It's a subset of deep learning, which involves training neural networks on large datasets to learn patterns and relationships in language.\\n\\nLLMs are designed to understand the meaning of words, phrases, and sentences, and to generate coherent and contextually relevant responses. They can be used for a wide range of applications, such as:\\n\\n1. Chatbots: LLMs can be used to power virtual assistants, like Siri or Alexa, that can understand voice commands and respond accordingly.\\n2. Content generation: LLMs can generate text articles, social media posts, and other types of content for businesses, researchers, and writers.\\n3. Language translation: LLMs can translate languages in real-time, allowing people to communicate with each other who speak different languages.\\n4. Summarization: LLMs can summarize long pieces of text into shorter, more digestible versions.\\n\\nLLMs typically consist of three main components:\\n\\n1. Training data: A massive dataset of text that the model is trained on.\\n2. Model architecture: The specific design of the neural network used to process and generate text.\\n3. Objective function: A measure of how well the model performs, such as predicting the likelihood of a given sentence being true.\\n\\nThere are several types of LLMs, including:\\n\\n1. transformer-based models (e.g., BERT, RoBERTa)\\n2. recurrent neural network (RNN)-based models\\n3. convolutional neural network (CNN)-based models\\n\\nLLMs have many advantages, including:\\n\\n* Ability to understand complex language structures and nuances\\n* Capacity to generate human-like text\\n* Scalability and speed of training\\n* Flexibility in domain-specific applications\\n\\nHowever, LLMs also have some limitations, such as:\\n\\n* Training data quality: If the training dataset is biased or lacks diversity, the model may learn these biases and perpetuate them.\\n* Overfitting: The model may become too specialized to the training data and fail to generalize well to new, unseen data.\\n* Interpretability: It can be difficult to understand why a particular output was generated, as the model's decision-making process is often complex.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing just in case\n",
    "llm.invoke(\"What is a LLM?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the PDFLoader from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"notes.pdf\")\n",
    "\n",
    "loaded_document = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the operational environments where systems\\nare  deployed.  Increased  consideration  of\\noperational security risk earlier in the acquisition\\nand  development  processes  provides  an\\nopportunity to tune decisions to address security\\nrisk  and  reduce  the  total  cost  of  operational\\nsecurity.  This  book  provides  key  operational\\nmanagement  approaches,  methodologies,  and\\npractices for assuring a greater level of software\\nand system security throughout the development\\nand acquisition lifecycle. \\nThis  book  contains  recommendations  to  guide\\nsoftware  professionals  in  creating  a\\ncomprehensive lifecycle process for system and\\nsoftware  security.  That  process  allows\\norganizations to incorporate widely accepted and\\nwell-defined assurance approaches into their own\\nspecific  methods  for  ensuring  operational\\nsecurity of their software and system assets. It’s\\nworth pointing out that the material in this book\\nis applicable to many different types of systems.\\nAlthough  many  of  our  recommendations\\noriginated from our work in information systems\\nsecurity,  the  recommendations  are  equally\\napplicable  to  systems  used  to  support  critical\\ninfrastructure, such as industrial control systems\\nand  SCADA  (supervisory  control  and  data\\nacquisition) systems. The same can be said for\\nother hardware/ software systems that are not\\n2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Content can be accessed through indexing as follows\n",
    "loaded_document[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RecursiveTextSplitter to convert the loaded text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =100,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(loaded_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community import embeddings\n",
    "\n",
    "embedding_model = embeddings.OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining ChromaDB (Vector Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    embedding=embedding_model,\n",
    "    documents=all_splits\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining type of search to be done and number of nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuva\\AppData\\Local\\Temp\\ipykernel_15632\\3535406044.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'page_label': '1', 'source': 'notes.pdf'}, page_content='In This Chapter \\n• 1.1 Introduction \\n• 1.2 What Do We Mean by Lifecycle Assurance?'),\n",
       " Document(metadata={'page': 3, 'page_label': '4', 'source': 'notes.pdf'}, page_content='software lifecycle. \\n1.2 What  Do  We  Mean  by  Lifecycle\\nAssurance?'),\n",
       " Document(metadata={'page': 8, 'page_label': '9', 'source': 'notes.pdf'}, page_content='for implementation and sustainment. As a result,\\nassurance must be planned across the lifecycle'),\n",
       " Document(metadata={'page': 8, 'page_label': '9', 'source': 'notes.pdf'}, page_content='lifecycle assurance [Mead 2010a]: \\nApplication  of  technologies  and  processes  to'),\n",
       " Document(metadata={'page': 16, 'page_label': '17', 'source': 'notes.pdf'}, page_content='assurance. \\n1.4 Addressing Lifecycle Assurance3 \\n3.  Material  in  this  section  comes  from'),\n",
       " Document(metadata={'page': 0, 'page_label': '1', 'source': 'notes.pdf'}, page_content='Assurance \\n• 1.4 Addressing Lifecycle Assurance\\n• 1.5 Case Studies Used in This Book')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing number of relevant documents which will be retrieved\n",
    "retriever.get_relevant_documents(\n",
    "    \"What is life-cycle assurance?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhuva\\Desktop\\crew-ai-agent\\env\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Importing prompt from Langchain hub\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(query):\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "    context = format_docs(docs)\n",
    "\n",
    "    #Generating answer based on initial context\n",
    "    intermediate_answer = llm.invoke(\n",
    "        f\"Based on the following information, provide a concise answer:\\n\\n{context}\"\n",
    "    )\n",
    "\n",
    "    #Expand the query\n",
    "    expanded_query = f\"{query} {intermediate_answer}\"\n",
    "\n",
    "    return expanded_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain_function(question):\n",
    "\n",
    "    #Normal Retrieval using the initial query\n",
    "    expanded_question = expand_query(question)\n",
    "\n",
    "    #Second retrieval using expanded query\n",
    "    refined_docs = retriever.invoke(expanded_question)\n",
    "    refined_context = format_docs(refined_docs)\n",
    "\n",
    "    #Generating final answer\n",
    "    final_answer = llm.invoke(\n",
    "        f\"Answer based on the following retrieved context:\\n\\n{refined_context}\"\n",
    "    )\n",
    "\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: Based on the provided context, here's an expanded version of the information:\n",
      "\n",
      "As the demand for flights continues to grow, the industry is shifting towards more efficient and customer-centric approaches. For example, for a Fly-By-Night Airlines, it would be beneficial to develop along with a frequent flyer program.\n",
      "\n",
      "To begin this process, capable devices in the targeted geographic area need to be implemented. This could include upgrading or introducing new technologies such as:\n",
      "\n",
      "* High-speed internet connectivity\n",
      "* Satellite communications\n",
      "* Advanced customer relationship management (CRM) systems\n",
      "\n",
      "One effective way to expand the number of passengers is by providing higher-quality service. This can be achieved through various initiatives, including:\n",
      "\n",
      "* Investing in modernized aircraft and crew training programs\n",
      "* Implementing advanced passenger experience features such as personalized check-in, mobile apps, and dedicated customer support teams\n",
      "* Enhancing security protocols to ensure a safe and secure travel experience\n",
      "\n",
      "It's worth noting that Fly-By-Night Airlines should also take advantage of emerging technologies like artificial intelligence (AI) and machine learning (ML) to enhance the passenger journey. These technologies can help automate routine tasks, improve decision-making, and provide more personalized experiences for passengers.\n",
      "\n",
      "Furthermore, a well-designed automated airline reservations system (ARS) is crucial for Fly-By-Night Airlines to manage operations efficiently. The chief financial officer has already acknowledged the need for this development. By implementing an ARS, Fly-By-Night Airlines can streamline processes, reduce costs, and improve overall efficiency.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Execute Query Expansion RAG\n",
    "query = \"Summarize the Fly-By-Night case study.\"\n",
    "final_response = rag_chain_function(query)\n",
    "\n",
    "print(\"\\nFinal Answer:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
